{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 class=\"alert alert-block alert-info\">GHI NH·ªö</h1>\n",
    "<ul>\n",
    "    <li>Th∆∞ vi·ªán</li>\n",
    "    <li>T·ª∑ l·ªá ??:?? v·ªõi random_state = ??</li>\n",
    "    <li>ƒê·ªçc ƒë·ªÅ</li>\n",
    "    <li>Chu·∫©n h√≥a d·ªØ li·ªáu ƒë·∫ßu v√†o tr√™n t·∫≠p hu·∫•n luy·ªán<br>\n",
    "            scaler = StandardScaler()<br>\n",
    "            X_train_scaled = scaler.fit_transform(X_train)<br>\n",
    "            X_test_scaled = scaler.transform(X_test)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2 class=\"alert alert-info\">1. M√¥ h√¨nh h·ªìi quy tuy·∫øn t√≠nh</H2>\n",
    "<h4>      model = LinearRegression()</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H·ªá s·ªë g√≥c c·ªßa bi·∫øn 'age' trong m√¥ h√¨nh hu·∫•n luy·ªán l√†: 0.8433884781639227\n",
      "MAPE: 0.2012807931898763\n",
      "H·ªá s·ªë t·ª± do (intercept): 22.12483516483517\n",
      "R-squared tr√™n t·∫≠p hu·∫•n luy·ªán: 0.5480883767100382\n",
      "MAP l√†: 0.2012807931898763\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.96775636, 0.91299676])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# ƒê·ªçc d·ªØ li·ªáu\n",
    "data = pd.read_csv('BostonHousing.csv')\n",
    "\n",
    "# T√°ch d·ªØ li·ªáu ƒë·∫ßu v√†o v√† ƒë·∫ßu ra\n",
    "X = data[['age', 'lstat']]\n",
    "y = data['medv']\n",
    "\n",
    "# T√°ch d·ªØ li·ªáu th√†nh t·∫≠p hu·∫•n luy·ªán v√† ki·ªÉm th·ª≠ theo t·ª∑ l·ªá 90:10 v·ªõi random_state = 10\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=10)\n",
    "\n",
    "# Chu·∫©n h√≥a d·ªØ li·ªáu ƒë·∫ßu v√†o tr√™n t·∫≠p hu·∫•n luy·ªán\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Hu·∫•n luy·ªán m√¥ h√¨nh h·ªìi quy tuy·∫øn t√≠nh\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# L·∫•y h·ªá s·ªë g√≥c c·ªßa bi·∫øn 'age'\n",
    "age_coefficient = model.coef_[0]\n",
    "print(\"H·ªá s·ªë g√≥c c·ªßa bi·∫øn 'age' trong m√¥ h√¨nh hu·∫•n luy·ªán l√†:\", age_coefficient)\n",
    "\n",
    "# D·ª± b√°o tr√™n t·∫≠p ki·ªÉm tra ƒë√£ chu·∫©n h√≥a\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# T√≠nh MAPE tr√™n d·ªØ li·ªáu ki·ªÉm tra ƒë√£ chu·∫©n h√≥a\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "print(f\"MAPE: {mape}\")\n",
    "\n",
    "# L·∫•y h·ªá s·ªë t·ª± do c·ªßa m√¥ h√¨nh\n",
    "intercept = model.intercept_\n",
    "print(f\"H·ªá s·ªë t·ª± do (intercept): {intercept}\")\n",
    "\n",
    "# d·ª±a v√†o t·∫≠p hu·∫•n luy·ªán th√¨ c√°c bi·∫øn ƒë·ªôc l·∫≠p gi·∫£i th√≠ch ƒë∆∞·ª£c bao nhi√™u ph·∫ßn trƒÉm s·ª± thay ƒë·ªïi c·ªßa bi·∫øn ph·ª• thu·ªôc\n",
    "# Gi·∫£ s·ª≠ b·∫°n ƒë√£ chu·∫©n h√≥a d·ªØ li·ªáu v√† hu·∫•n luy·ªán m√¥ h√¨nh nh∆∞ ƒë√£ l√†m tr∆∞·ªõc ƒë√≥\n",
    "r_squared = model.score(X_train_scaled, y_train)\n",
    "print(f\"R-squared tr√™n t·∫≠p hu·∫•n luy·ªán: {r_squared}\")\n",
    "\n",
    "# T√≠nh MAPE\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "print(f\"MAP l√†: {mape}\")\n",
    "\n",
    "# Hi·ªÉn th·ªã h√†ng ƒë·∫ßu ti√™n c·ªßa d·ªØ li·ªáu ƒë·∫ßu v√†o ƒë√†o t·∫°o chu·∫©n h√≥a\n",
    "X_train_scaled[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 2)\n",
      "(51, 2)\n",
      "(455,)\n",
      "(51,)\n",
      "(51, 2)\n",
      "(455, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(X_test_scaled.shape)\n",
    "print(X_train_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.539788169192043\n"
     ]
    }
   ],
   "source": [
    "# D·ª± b√°o gi√° tr·ªã c·ªßa medv khi age = 37.5 v√† lstat = 4.65\n",
    "predicted_medv = model.predict([[37.5, 4.65]])\n",
    "print(predicted_medv[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 class=\"alert alert-info\">2. M√¥ h√¨nh KNN (N_neighbors =?)</h2>\n",
    "<h4># X√¢y d·ª±ng v√† hu·∫•n luy·ªán m√¥ h√¨nh KNN <br>\n",
    "knn = KNeighborsClassifier(n_neighbors=3) <br>\n",
    "knn.fit(X_train_scaled, y_train)</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M·ª•c ƒë√≠ch s·ª≠ d·ª•ng:\n",
    "\n",
    "KNeighborsRegressor: D√πng cho h·ªìi quy (gi√° tr·ªã li√™n t·ª•c).\n",
    "\n",
    "KNeighborsClassifier: D√πng cho ph√¢n lo·∫°i (nh√£n ph√¢n lo·∫°i).\n",
    "\n",
    "ƒê·∫ßu ra:\n",
    "\n",
    "KNeighborsRegressor: Gi√° tr·ªã s·ªë li√™n t·ª•c.\n",
    "\n",
    "KNeighborsClassifier: Nh√£n ph√¢n lo·∫°i.\n",
    "\n",
    "Khi n√†o s·ª≠ d·ª•ng lo·∫°i n√†o?\n",
    "N·∫øu b√†i to√°n c·ªßa b·∫°n y√™u c·∫ßu d·ª± b√°o m·ªôt gi√° tr·ªã s·ªë li√™n t·ª•c (nh∆∞ gi√° nh√†, nhi·ªát ƒë·ªô, ...), b·∫°n n√™n s·ª≠ d·ª•ng KNeighborsRegressor.\n",
    "\n",
    "N·∫øu b√†i to√°n c·ªßa b·∫°n y√™u c·∫ßu ph√¢n lo·∫°i m·ªôt ƒë·ªëi t∆∞·ª£ng v√†o c√°c nh√≥m ho·∫∑c l·ªõp c·ª• th·ªÉ (nh∆∞ d·ª± ƒëo√°n lo√†i hoa, ph√¢n lo·∫°i th∆∞ t√≠n, ...), b·∫°n n√™n s·ª≠ d·ª•ng KNeighborsClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE: 0.2068515147120001\n",
      "R-squared tr√™n t·∫≠p ki·ªÉm tra: 0.3707806817392786\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "\n",
    "# ƒê·ªçc d·ªØ li·ªáu\n",
    "data = pd.read_csv('BostonHousing.csv')\n",
    "\n",
    "# T√°ch bi·∫øn ƒë·∫ßu v√†o v√† ƒë·∫ßu ra\n",
    "X = data[['age', 'lstat']]\n",
    "y = data['medv']\n",
    "\n",
    "# Chia d·ªØ li·ªáu th√†nh t·∫≠p hu·∫•n luy·ªán v√† t·∫≠p ki·ªÉm tra\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=10)\n",
    "\n",
    "# Chu·∫©n h√≥a d·ªØ li·ªáu\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# X√¢y d·ª±ng v√† hu·∫•n luy·ªán m√¥ h√¨nh KNN h·ªìi quy\n",
    "knn = KNeighborsRegressor(n_neighbors=1) # or KNeighborsClassifier\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# D·ª± b√°o v√† ƒë√°nh gi√° m√¥ h√¨nh\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MAPE: {mape}\")\n",
    "print(f\"R-squared tr√™n t·∫≠p ki·ªÉm tra: {r_squared}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 class=\"alert alert-block alert-info\">3. Decision Tree</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>DecisionTreeRegressor:</h2> S·ª≠ d·ª•ng cho b√†i to√°n h·ªìi quy, v·ªõi bi·∫øn m·ª•c ti√™u l√† c√°c gi√° tr·ªã li√™n t·ª•c. ƒê√°nh gi√° m√¥ h√¨nh b·∫±ng Mean Squared Error (MSE), R-squared, Mean Absolute Error (MAE), v.v."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 65.51333333333335\n",
      "R-squared tr√™n t·∫≠p ki·ªÉm tra: 0.33827033368071513\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# ƒê·ªçc d·ªØ li·ªáu\n",
    "data = pd.read_csv('BostonHousing.csv')\n",
    "\n",
    "# T√°ch bi·∫øn ƒë·∫ßu v√†o v√† ƒë·∫ßu ra\n",
    "X = data[['age', 'lstat']]\n",
    "y = data['medv']\n",
    "\n",
    "# Chia d·ªØ li·ªáu th√†nh t·∫≠p hu·∫•n luy·ªán v√† t·∫≠p ki·ªÉm tra\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=10)\n",
    "\n",
    "# Chu·∫©n h√≥a d·ªØ li·ªáu\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# X√¢y d·ª±ng v√† hu·∫•n luy·ªán m√¥ h√¨nh c√¢y quy·∫øt ƒë·ªãnh h·ªìi quy\n",
    "tree = DecisionTreeRegressor(random_state=42)\n",
    "tree.fit(X_train_scaled, y_train)\n",
    "\n",
    "# D·ª± b√°o v√† ƒë√°nh gi√° m√¥ h√¨nh\n",
    "y_pred = tree.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared tr√™n t·∫≠p ki·ªÉm tra: {r_squared}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>DecisionTreeClassifier:</h2> S·ª≠ d·ª•ng cho b√†i to√°n ph√¢n lo·∫°i, v·ªõi bi·∫øn m·ª•c ti√™u l√† c√°c nh√£n ph√¢n lo·∫°i. ƒê√°nh gi√° m√¥ h√¨nh b·∫±ng ƒë·ªô ch√≠nh x√°c (accuracy) ho·∫∑c c√°c ch·ªâ s·ªë kh√°c nh∆∞ precision, recall, F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒê·ªô ch√≠nh x√°c c·ªßa m√¥ h√¨nh: 33.33%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Chu·∫©n b·ªã d·ªØ li·ªáu\n",
    "data = {\n",
    "    'S·ª©c kh·ªèe': ['·ªëm', '·ªëm', '·ªëm', '·ªëm', 't·ªët', 't·ªët', 't·ªët'],\n",
    "    'Th·ªùi ti·∫øt': ['u √°m', 'm∆∞a', 'n·∫Øng', 'u √°m', 'u √°m', 'm∆∞a', 'n·∫Øng'],\n",
    "    'K·∫øt qu·∫£': ['c√≥', 'c√≥', 'kh√¥ng', 'c√≥', 'kh√¥ng', 'kh√¥ng', 'c√≥']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Chuy·ªÉn ƒë·ªïi c√°c gi√° tr·ªã ph√¢n lo·∫°i th√†nh s·ªë\n",
    "le = LabelEncoder()\n",
    "df['S·ª©c kh·ªèe'] = le.fit_transform(df['S·ª©c kh·ªèe'])\n",
    "df['Th·ªùi ti·∫øt'] = le.fit_transform(df['Th·ªùi ti·∫øt'])\n",
    "df['K·∫øt qu·∫£'] = le.fit_transform(df['K·∫øt qu·∫£'])\n",
    "\n",
    "# T√°ch bi·∫øn ƒë·∫ßu v√†o v√† ƒë·∫ßu ra\n",
    "X = df[['S·ª©c kh·ªèe', 'Th·ªùi ti·∫øt']]\n",
    "y = df['K·∫øt qu·∫£']\n",
    "\n",
    "# Chia d·ªØ li·ªáu th√†nh t·∫≠p hu·∫•n luy·ªán v√† t·∫≠p ki·ªÉm tra\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# X√¢y d·ª±ng v√† hu·∫•n luy·ªán m√¥ h√¨nh c√¢y quy·∫øt ƒë·ªãnh ph√¢n lo·∫°i\n",
    "tree_classifier = DecisionTreeClassifier(random_state=42)\n",
    "tree_classifier.fit(X_train, y_train)\n",
    "\n",
    "# D·ª± b√°o v√† ƒë√°nh gi√° m√¥ h√¨nh\n",
    "y_pred = tree_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"ƒê·ªô ch√≠nh x√°c c·ªßa m√¥ h√¨nh: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 class=\"alert alert-block alert-info\">4. Bayesian</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "m√¥ h√¨nh bayesia\n",
    "M√¥ h√¨nh Bayes (Bayesian model) l√† m·ªôt ph∆∞∆°ng ph√°p m·∫°nh m·∫Ω trong h·ªçc m√°y v√† th·ªëng k√™, d·ª±a tr√™n ƒë·ªãnh l√Ω Bayes. C√°c m√¥ h√¨nh n√†y th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ƒë∆∞a ra d·ª± ƒëo√°n v√† ph√¢n lo·∫°i d·ª±a tr√™n x√°c su·∫•t. D∆∞·ªõi ƒë√¢y l√† m·ªôt s·ªë kh√°i ni·ªám ch√≠nh v√† ·ª©ng d·ª•ng c·ªßa m√¥ h√¨nh Bayes:\n",
    "\n",
    "ƒê·ªãnh l√Ω Bayes:\n",
    "ƒê·ªãnh l√Ω Bayes m√¥ t·∫£ x√°c su·∫•t c√≥ ƒëi·ªÅu ki·ªán v√† m·ªëi quan h·ªá gi·ªØa x√°c su·∫•t c·ªßa hai bi·∫øn s·ª± ki·ªán:\n",
    "\n",
    "ùëÉ\n",
    "(\n",
    "ùê¥\n",
    "‚à£\n",
    "ùêµ\n",
    ")\n",
    "\"=\"\n",
    "ùëÉ\n",
    "(\n",
    "ùêµ\n",
    "‚à£\n",
    "ùê¥\n",
    ")\n",
    "‚ãÖ\n",
    "ùëÉ\n",
    "(\n",
    "ùê¥\n",
    ")\n",
    " / ùëÉ\n",
    "(\n",
    "ùêµ\n",
    ")<br>\n",
    "Trong ƒë√≥:\n",
    "\n",
    "ùëÉ\n",
    "(\n",
    "ùê¥\n",
    "‚à£\n",
    "ùêµ\n",
    ")\n",
    " l√† x√°c su·∫•t c·ªßa s·ª± ki·ªán A x·∫£y ra khi bi·∫øt B ƒë√£ x·∫£y ra.\n",
    "\n",
    "ùëÉ\n",
    "(\n",
    "ùêµ\n",
    "‚à£\n",
    "ùê¥\n",
    ")\n",
    " l√† x√°c su·∫•t c·ªßa s·ª± ki·ªán B x·∫£y ra khi bi·∫øt A ƒë√£ x·∫£y ra.\n",
    "\n",
    "ùëÉ\n",
    "(\n",
    "ùê¥\n",
    ")\n",
    " v√† \n",
    "ùëÉ\n",
    "(\n",
    "ùêµ\n",
    ")\n",
    " l√† x√°c su·∫•t c·ªßa s·ª± ki·ªán A v√† B x·∫£y ra ƒë·ªôc l·∫≠p."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Naive Bayes:</h3>\n",
    "\n",
    "Gi·∫£ ƒë·ªãnh ƒë∆°n gi·∫£n: C√°c ƒë·∫∑c tr∆∞ng l√† ƒë·ªôc l·∫≠p v·ªõi nhau.\n",
    "\n",
    "·ª®ng d·ª•ng: Ph√¢n lo·∫°i vƒÉn b·∫£n (spam detection), ph√¢n lo·∫°i h√¨nh ·∫£nh, ph√¢n lo·∫°i c·∫£m x√∫c, v.v.\n",
    "\n",
    "∆Øu ƒëi·ªÉm: Nhanh ch√≥ng, hi·ªáu qu·∫£, d·ªÖ tri·ªÉn khai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒê·ªô ch√≠nh x√°c c·ªßa m√¥ h√¨nh: 0.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# D·ªØ li·ªáu m·∫´u\n",
    "texts = [\"I love this movie\", \"I hate this movie\", \"This is the best movie\", \"This is the worst movie\"]\n",
    "labels = [\"positive\", \"negative\", \"positive\", \"negative\"]\n",
    "\n",
    "# Chuy·ªÉn ƒë·ªïi vƒÉn b·∫£n th√†nh ma tr·∫≠n ƒë·∫øm t·ª´\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(texts)\n",
    "y = labels\n",
    "\n",
    "# Chia d·ªØ li·ªáu th√†nh t·∫≠p hu·∫•n luy·ªán v√† t·∫≠p ki·ªÉm tra\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# X√¢y d·ª±ng v√† hu·∫•n luy·ªán m√¥ h√¨nh Naive Bayes\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# D·ª± b√°o v√† ƒë√°nh gi√° m√¥ h√¨nh\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"ƒê·ªô ch√≠nh x√°c c·ªßa m√¥ h√¨nh: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒê·ªô ch√≠nh x√°c c·ªßa m√¥ h√¨nh: 66.67%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Chu·∫©n b·ªã d·ªØ li·ªáu\n",
    "data = {\n",
    "    'S·ª©c kh·ªèe': ['·ªëm', '·ªëm', '·ªëm', '·ªëm', 't·ªët', 't·ªët', 't·ªët'],\n",
    "    'Th·ªùi ti·∫øt': ['u √°m', 'm∆∞a', 'n·∫Øng', 'u √°m', 'u √°m', 'm∆∞a', 'n·∫Øng'],\n",
    "    'K·∫øt qu·∫£': ['c√≥', 'c√≥', 'kh√¥ng', 'c√≥', 'kh√¥ng', 'kh√¥ng', 'c√≥']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Chuy·ªÉn ƒë·ªïi c√°c gi√° tr·ªã ph√¢n lo·∫°i th√†nh s·ªë\n",
    "le = LabelEncoder()\n",
    "df['S·ª©c kh·ªèe'] = le.fit_transform(df['S·ª©c kh·ªèe'])\n",
    "df['Th·ªùi ti·∫øt'] = le.fit_transform(df['Th·ªùi ti·∫øt'])\n",
    "df['K·∫øt qu·∫£'] = le.fit_transform(df['K·∫øt qu·∫£'])\n",
    "\n",
    "# T√°ch bi·∫øn ƒë·∫ßu v√†o v√† ƒë·∫ßu ra\n",
    "X = df[['S·ª©c kh·ªèe', 'Th·ªùi ti·∫øt']]\n",
    "y = df['K·∫øt qu·∫£']\n",
    "\n",
    "# Chia d·ªØ li·ªáu th√†nh t·∫≠p hu·∫•n luy·ªán v√† t·∫≠p ki·ªÉm tra\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# X√¢y d·ª±ng v√† hu·∫•n luy·ªán m√¥ h√¨nh Naive Bayes\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# D·ª± b√°o v√† ƒë√°nh gi√° m√¥ h√¨nh\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"ƒê·ªô ch√≠nh x√°c c·ªßa m√¥ h√¨nh: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 class=\"alert alert-block alert-info\">5. H·ªìi quy tuy·∫øn t√≠nh b·ªôi (Multiple Linear Regression)</h1>\n",
    " l√† m·ªôt ph∆∞∆°ng ph√°p d√πng ƒë·ªÉ m√¥ h√¨nh h√≥a m·ªëi quan h·ªá gi·ªØa m·ªôt bi·∫øn m·ª•c ti√™u (dependent variable) v√† nhi·ªÅu bi·∫øn ƒë·∫ßu v√†o (independent variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 49.312606628201\n",
      "R-squared tr√™n t·∫≠p ki·ªÉm tra: 0.5019088013216607\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# ƒê·ªçc d·ªØ li·ªáu\n",
    "data = pd.read_csv('BostonHousing.csv')\n",
    "\n",
    "# T√°ch bi·∫øn ƒë·∫ßu v√†o v√† ƒë·∫ßu ra\n",
    "X = data[['age', 'lstat']]\n",
    "y = data['medv']\n",
    "\n",
    "# Chia d·ªØ li·ªáu th√†nh t·∫≠p hu·∫•n luy·ªán v√† t·∫≠p ki·ªÉm tra\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=10)\n",
    "\n",
    "# Chu·∫©n h√≥a d·ªØ li·ªáu\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# X√¢y d·ª±ng v√† hu·∫•n luy·ªán m√¥ h√¨nh h·ªìi quy tuy·∫øn t√≠nh b·ªôi\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# D·ª± b√°o v√† ƒë√°nh gi√° m√¥ h√¨nh\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared tr√™n t·∫≠p ki·ªÉm tra: {r_squared}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gi√° tr·ªã d·ª± b√°o c·ªßa medv: 29.454798629362067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Gi√° tr·ªã m·ªõi c·ªßa age v√† lstat\n",
    "new_data = np.array([[37.5, 4.65]])\n",
    "\n",
    "# Chu·∫©n h√≥a gi√° tr·ªã ƒë·∫ßu v√†o m·ªõi\n",
    "new_data_scaled = scaler.transform(new_data)\n",
    "\n",
    "# D·ª± b√°o gi√° tr·ªã medv\n",
    "predicted_medv = model.predict(new_data_scaled)\n",
    "print(f\"Gi√° tr·ªã d·ª± b√°o c·ªßa medv: {predicted_medv[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div  class=\"alert alert-block alert-info\">\n",
    "    <h1>Links</h1>\n",
    "    <a href=\"https://intellipaat.com/blog/what-is-linear-regression/?US#Boston-Housing-Prices-Dataset\"> H·ªìi quy tuy·∫øn t√≠nh</a><br>\n",
    "    <a href=\"https://github.com/flexeduvn/nmptdlai\"> Code Github</a><br>\n",
    "    <a href=\"https://github.com/TMHuinh/ptdl\"> Data c√° nh√¢n</a>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
